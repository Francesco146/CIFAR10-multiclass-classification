{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLpkKHw9121wUyjPgR+yUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francesco146/machine-learning-project/blob/master/Machine_Learning_Pasotto_Marastoni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rksKZNPkqSlM",
        "outputId": "a504e37b-d6cf-4fd2-e3a9-b6d9fe2738ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-11 13:59:18--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs231n.stanford.edu/tiny-imagenet-200.zip [following]\n",
            "--2025-01-11 13:59:18--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  6.83MB/s    in 29s     \n",
            "\n",
            "2025-01-11 13:59:47 (8.23 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200\n",
        "!rm -rf tiny-imagenet-200.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "DATA_DIR = 'tiny-imagenet-200'\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
        "\n",
        "val_data = pd.read_csv(f'{VAL_DIR}/val_annotations.txt',\n",
        "                       sep='\\t',\n",
        "                       header=None,\n",
        "                       names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "\n",
        "val_data.head()\n",
        "\n",
        "val_img_dir = os.path.join(VAL_DIR, 'images')\n",
        "\n",
        "fp = open(os.path.join(VAL_DIR, 'val_annotations.txt'), 'r')\n",
        "data = fp.readlines()\n",
        "\n",
        "val_img_dict = {}\n",
        "for line in data:\n",
        "  words = line.split('\\t')\n",
        "  val_img_dict[words[0]] = words[1]\n",
        "fp.close()\n",
        "\n",
        "{k: val_img_dict[k] for k in list(val_img_dict)[:10]}\n",
        "\n",
        "for img, folder in val_img_dict.items():\n",
        "  new_path = (os.path.join(val_img_dir, folder))\n",
        "  if not os.path.exists(new_path):\n",
        "    os.makedirs(new_path)\n",
        "  if os.path.exists(os.path.join(val_img_dir, img)):\n",
        "    os.rename(os.path.join(val_img_dir, img), os.path.join(new_path, img))\n",
        "class_to_name_dict = dict()\n",
        "fp = open(os.path.join(DATA_DIR, 'words.txt'), 'r')\n",
        "data = fp.readlines()\n",
        "for line in data:\n",
        "  words = line.strip('\\n').split('\\t')\n",
        "  class_to_name_dict[words[0]] = words[1].split(',')[0]\n",
        "fp.close()\n",
        "\n",
        "{k: class_to_name_dict[k] for k in list(class_to_name_dict)[:20]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0w6YJz6qh4-",
        "outputId": "00ee31c6-bcf9-4d52-c3eb-b591373003c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n00001740': 'entity',\n",
              " 'n00001930': 'physical entity',\n",
              " 'n00002137': 'abstraction',\n",
              " 'n00002452': 'thing',\n",
              " 'n00002684': 'object',\n",
              " 'n00003553': 'whole',\n",
              " 'n00003993': 'congener',\n",
              " 'n00004258': 'living thing',\n",
              " 'n00004475': 'organism',\n",
              " 'n00005787': 'benthos',\n",
              " 'n00005930': 'dwarf',\n",
              " 'n00006024': 'heterotroph',\n",
              " 'n00006150': 'parent',\n",
              " 'n00006269': 'life',\n",
              " 'n00006400': 'biont',\n",
              " 'n00006484': 'cell',\n",
              " 'n00007347': 'causal agent',\n",
              " 'n00007846': 'person',\n",
              " 'n00015388': 'animal',\n",
              " 'n00017222': 'plant'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "class TinyImageNet(Dataset):\n",
        "  _TRAIN_DIR = TRAIN_DIR\n",
        "  _VAL_DIR = val_img_dir\n",
        "\n",
        "  def __init__(self, split = 'train', transform = None):\n",
        "    super().__init__()\n",
        "    self.transform = transform\n",
        "\n",
        "    match split:\n",
        "      case 'train':\n",
        "        dataset = ImageFolder(root=self._TRAIN_DIR, transform=transforms.ToTensor())\n",
        "      case 'val':\n",
        "        dataset = ImageFolder(root=self._VAL_DIR, transform=transforms.ToTensor())\n",
        "      case _:\n",
        "        raise ValueError(f'Invalid split: {split}')\n",
        "\n",
        "    self.imgs_path = np.array(dataset.imgs)\n",
        "    self.labels = np.array(dataset.targets)\n",
        "    self.n_classes = len(dataset.classes)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs_path)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path, label = self.imgs_path[idx]\n",
        "    img = torchvision.io.read_image(img_path)\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "aLoqvLRWyXiu"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}